{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgdoRVUpoXOL"
      },
      "source": [
        "# Assignment 1 - Code Example - Part A\n",
        "\n",
        "This code baseline is inspired by and modified from [this great tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html).\n",
        "\n",
        "This code can achieve an accuracy of approximately 86.50% on CIFAR-10. Please set up the environment and run your experiments starting from this baseline. You are expected to achieve an accuracy higher than this baseline."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yej3QZ2grjpX",
        "outputId": "9ffab519-efad-43cd-f7c8-37e08555922c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (780.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nvtx-cu12-12.1.105 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USZI1D7CoXON"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as tv_datasets\n",
        "import torchvision.transforms as tv_transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1naIfNSoXON"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters 🔄 Increased batch size, reduced epochs\n",
        "num_epochs = 100\n",
        "batch_size = 256\n",
        "num_workers = 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Data Augmentation 🔄 Added cutout and color jitter\n",
        "train_transform = tv_transforms.Compose([\n",
        "    tv_transforms.RandomCrop(32, padding=4),\n",
        "    tv_transforms.RandomHorizontalFlip(),\n",
        "    tv_transforms.RandomRotation(15),\n",
        "    tv_transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    tv_transforms.ToTensor(),\n",
        "    tv_transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
        "])\n",
        "\n",
        "test_transform = tv_transforms.Compose([\n",
        "    tv_transforms.ToTensor(),\n",
        "    tv_transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
        "])"
      ],
      "metadata": {
        "id": "idE7HzmXuzOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHUQPIZroXOO"
      },
      "outputs": [],
      "source": [
        "# # prepare datasets\n",
        "# dataset, loader = {}, {}\n",
        "# for data_type in (\"train\", \"test\"):\n",
        "#     is_train = data_type==\"train\"\n",
        "#     dataset[data_type] = tv_datasets.CIFAR10(\n",
        "#         root=\"./data\", train=is_train, download=True, transform=transformation[data_type],\n",
        "#     )\n",
        "#     loader[data_type] = torch.utils.data.DataLoader(\n",
        "#         dataset[data_type], batch_size=batch_size, shuffle=is_train, num_workers=num_workers,\n",
        "#     )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 datasets\n",
        "train_dataset = tv_datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=train_transform)\n",
        "test_dataset = tv_datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc4ystyVvMBU",
        "outputId": "ceb6cc4e-5c95-41f8-c2df-8b28ac8ef907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 42.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-nPpNQ_oXOO"
      },
      "outputs": [],
      "source": [
        "# # our network architecture\n",
        "# net = nn.Sequential(\n",
        "#     nn.Conv2d(3, 128, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n",
        "#     nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n",
        "#     nn.Conv2d(256, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
        "#     nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
        "#     nn.Conv2d(512, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n",
        "#     nn.Flatten(),\n",
        "#     nn.Linear(256 * 4 * 4, 512), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
        "#     nn.Linear(512, 256), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
        "#     nn.Linear(256, 128), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
        "#     nn.Linear(128, 10),\n",
        "# )\n",
        "\n",
        "# # move to device\n",
        "# net.to(device)\n",
        "\n",
        "# # print the number of parameters\n",
        "# print(f\"number of parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad) / 1_000_000:.2f}M\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Network Architecture 🔄 Added residual connections\n",
        "class ImprovedNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(256, 512, 3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 10))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "net = ImprovedNet().to(device)\n",
        "print(f\"Parameters: {sum(p.numel() for p in net.parameters())/1e6:.2f}M\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RHLavK7vRQb",
        "outputId": "84a278e1-0c9c-4171-d87c-e4efd714d074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters: 1.62M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l7Z63iqoXOO"
      },
      "source": [
        "## Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWgEa_VZoXOO"
      },
      "outputs": [],
      "source": [
        "# # the network optimizer\n",
        "# optimizer = getattr(optim, optim_name)(net.parameters(), **optim_kwargs)\n",
        "\n",
        "# # loss function\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# # training loop\n",
        "# net.train()\n",
        "# for epoch in range(num_epochs):\n",
        "\n",
        "#     running_loss = 0.0\n",
        "#     for i, (img, target) in enumerate(loader[\"train\"]):\n",
        "#         img, target = img.to(device), target.to(device)\n",
        "\n",
        "#         pred = net(img)\n",
        "#         loss = criterion(pred, target)\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         # print statistics\n",
        "#         running_loss += loss.item()\n",
        "#         if i % print_every == print_every - 1:\n",
        "#             print(f\"[epoch={epoch + 1:3d}, iter={i + 1:5d}] loss: {running_loss / print_every:.3f}\")\n",
        "#             running_loss = 0.0\n",
        "\n",
        "# print(\"Finished Training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzciD5j9oXOP"
      },
      "source": [
        "## Evaluating its accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Setup 🔄 Added label smoothing\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = optim.AdamW(net.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "# Training Loop with Validation 🔄 Added validation tracking\n",
        "best_acc = 0.0\n",
        "train_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    # Validation\n",
        "    net.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = net(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    val_accuracies.append(acc)\n",
        "    train_losses.append(running_loss/len(train_loader))\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {train_losses[-1]:.4f} | Acc: {acc:.2f}%\")\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        torch.save(net.state_dict(), \"best_cifar_model.pth\")\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "print(f\"\\nBest CIFAR-10 Accuracy: {best_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPEOLHS1vZxg",
        "outputId": "db59258b-c3a4-4f65-9005-a87d3cc0fe88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 | Loss: 1.7401 | Acc: 49.97%\n",
            "Epoch 2/100 | Loss: 1.4886 | Acc: 50.24%\n",
            "Epoch 3/100 | Loss: 1.3925 | Acc: 56.70%\n",
            "Epoch 4/100 | Loss: 1.3296 | Acc: 50.69%\n",
            "Epoch 5/100 | Loss: 1.2777 | Acc: 63.80%\n",
            "Epoch 6/100 | Loss: 1.2302 | Acc: 58.06%\n",
            "Epoch 7/100 | Loss: 1.1987 | Acc: 62.36%\n",
            "Epoch 8/100 | Loss: 1.1694 | Acc: 69.85%\n",
            "Epoch 9/100 | Loss: 1.1397 | Acc: 69.51%\n",
            "Epoch 10/100 | Loss: 1.1155 | Acc: 71.34%\n",
            "Epoch 11/100 | Loss: 1.0965 | Acc: 71.34%\n",
            "Epoch 12/100 | Loss: 1.0713 | Acc: 66.44%\n",
            "Epoch 13/100 | Loss: 1.0571 | Acc: 70.30%\n",
            "Epoch 14/100 | Loss: 1.0444 | Acc: 75.04%\n",
            "Epoch 15/100 | Loss: 1.0320 | Acc: 72.64%\n",
            "Epoch 16/100 | Loss: 1.0147 | Acc: 74.24%\n",
            "Epoch 17/100 | Loss: 0.9993 | Acc: 76.05%\n",
            "Epoch 18/100 | Loss: 0.9854 | Acc: 77.18%\n",
            "Epoch 19/100 | Loss: 0.9778 | Acc: 79.56%\n",
            "Epoch 20/100 | Loss: 0.9679 | Acc: 79.42%\n",
            "Epoch 21/100 | Loss: 0.9551 | Acc: 78.11%\n",
            "Epoch 22/100 | Loss: 0.9457 | Acc: 78.35%\n",
            "Epoch 23/100 | Loss: 0.9344 | Acc: 78.97%\n",
            "Epoch 24/100 | Loss: 0.9266 | Acc: 82.06%\n",
            "Epoch 25/100 | Loss: 0.9170 | Acc: 78.86%\n",
            "Epoch 26/100 | Loss: 0.9100 | Acc: 81.65%\n",
            "Epoch 27/100 | Loss: 0.9014 | Acc: 80.36%\n",
            "Epoch 28/100 | Loss: 0.9006 | Acc: 81.93%\n",
            "Epoch 29/100 | Loss: 0.8890 | Acc: 84.41%\n",
            "Epoch 30/100 | Loss: 0.8807 | Acc: 80.54%\n",
            "Epoch 31/100 | Loss: 0.8752 | Acc: 81.70%\n",
            "Epoch 32/100 | Loss: 0.8673 | Acc: 84.11%\n",
            "Epoch 33/100 | Loss: 0.8600 | Acc: 82.11%\n",
            "Epoch 34/100 | Loss: 0.8538 | Acc: 81.47%\n",
            "Epoch 35/100 | Loss: 0.8461 | Acc: 84.04%\n",
            "Epoch 36/100 | Loss: 0.8425 | Acc: 84.71%\n",
            "Epoch 37/100 | Loss: 0.8355 | Acc: 83.36%\n",
            "Epoch 38/100 | Loss: 0.8277 | Acc: 83.04%\n",
            "Epoch 39/100 | Loss: 0.8222 | Acc: 83.15%\n",
            "Epoch 40/100 | Loss: 0.8203 | Acc: 85.54%\n",
            "Epoch 41/100 | Loss: 0.8169 | Acc: 85.54%\n",
            "Epoch 42/100 | Loss: 0.8096 | Acc: 86.29%\n",
            "Epoch 43/100 | Loss: 0.8039 | Acc: 85.71%\n",
            "Epoch 44/100 | Loss: 0.7963 | Acc: 86.55%\n",
            "Epoch 45/100 | Loss: 0.7916 | Acc: 85.58%\n",
            "Epoch 46/100 | Loss: 0.7892 | Acc: 87.46%\n",
            "Epoch 47/100 | Loss: 0.7864 | Acc: 84.21%\n",
            "Epoch 48/100 | Loss: 0.7865 | Acc: 84.55%\n",
            "Epoch 49/100 | Loss: 0.7778 | Acc: 85.88%\n",
            "Epoch 50/100 | Loss: 0.7743 | Acc: 87.21%\n",
            "Epoch 51/100 | Loss: 0.7680 | Acc: 86.40%\n",
            "Epoch 52/100 | Loss: 0.7640 | Acc: 86.68%\n",
            "Epoch 53/100 | Loss: 0.7598 | Acc: 87.57%\n",
            "Epoch 54/100 | Loss: 0.7538 | Acc: 87.85%\n",
            "Epoch 55/100 | Loss: 0.7533 | Acc: 86.64%\n",
            "Epoch 56/100 | Loss: 0.7501 | Acc: 87.15%\n",
            "Epoch 57/100 | Loss: 0.7460 | Acc: 87.49%\n",
            "Epoch 58/100 | Loss: 0.7406 | Acc: 87.18%\n",
            "Epoch 59/100 | Loss: 0.7381 | Acc: 87.62%\n",
            "Epoch 60/100 | Loss: 0.7337 | Acc: 87.38%\n",
            "Epoch 61/100 | Loss: 0.7353 | Acc: 88.28%\n",
            "Epoch 62/100 | Loss: 0.7281 | Acc: 86.76%\n",
            "Epoch 63/100 | Loss: 0.7280 | Acc: 88.17%\n",
            "Epoch 64/100 | Loss: 0.7251 | Acc: 87.98%\n",
            "Epoch 65/100 | Loss: 0.7196 | Acc: 88.71%\n",
            "Epoch 66/100 | Loss: 0.7171 | Acc: 88.15%\n",
            "Epoch 67/100 | Loss: 0.7159 | Acc: 88.04%\n",
            "Epoch 68/100 | Loss: 0.7119 | Acc: 88.62%\n",
            "Epoch 69/100 | Loss: 0.7125 | Acc: 88.80%\n",
            "Epoch 70/100 | Loss: 0.7090 | Acc: 88.56%\n",
            "Epoch 71/100 | Loss: 0.7053 | Acc: 88.03%\n",
            "Epoch 72/100 | Loss: 0.7031 | Acc: 88.94%\n",
            "Epoch 73/100 | Loss: 0.6987 | Acc: 89.05%\n",
            "Epoch 74/100 | Loss: 0.6977 | Acc: 89.22%\n",
            "Epoch 75/100 | Loss: 0.6969 | Acc: 88.85%\n",
            "Epoch 76/100 | Loss: 0.6958 | Acc: 89.11%\n",
            "Epoch 77/100 | Loss: 0.6937 | Acc: 88.96%\n",
            "Epoch 78/100 | Loss: 0.6932 | Acc: 89.27%\n",
            "Epoch 79/100 | Loss: 0.6887 | Acc: 89.28%\n",
            "Epoch 80/100 | Loss: 0.6904 | Acc: 89.34%\n",
            "Epoch 81/100 | Loss: 0.6874 | Acc: 89.24%\n",
            "Epoch 82/100 | Loss: 0.6850 | Acc: 89.21%\n",
            "Epoch 83/100 | Loss: 0.6838 | Acc: 89.06%\n",
            "Epoch 84/100 | Loss: 0.6822 | Acc: 89.44%\n",
            "Epoch 85/100 | Loss: 0.6798 | Acc: 89.41%\n",
            "Epoch 86/100 | Loss: 0.6798 | Acc: 89.47%\n",
            "Epoch 87/100 | Loss: 0.6797 | Acc: 89.27%\n",
            "Epoch 88/100 | Loss: 0.6783 | Acc: 89.65%\n",
            "Epoch 89/100 | Loss: 0.6788 | Acc: 89.73%\n",
            "Epoch 90/100 | Loss: 0.6767 | Acc: 89.54%\n",
            "Epoch 91/100 | Loss: 0.6771 | Acc: 89.46%\n",
            "Epoch 92/100 | Loss: 0.6753 | Acc: 89.78%\n",
            "Epoch 93/100 | Loss: 0.6764 | Acc: 89.68%\n",
            "Epoch 94/100 | Loss: 0.6765 | Acc: 89.65%\n",
            "Epoch 95/100 | Loss: 0.6744 | Acc: 89.71%\n",
            "Epoch 96/100 | Loss: 0.6741 | Acc: 89.75%\n",
            "Epoch 97/100 | Loss: 0.6769 | Acc: 89.64%\n",
            "Epoch 98/100 | Loss: 0.6751 | Acc: 89.62%\n",
            "Epoch 99/100 | Loss: 0.6760 | Acc: 89.55%\n",
            "Epoch 100/100 | Loss: 0.6745 | Acc: 89.72%\n",
            "\n",
            "Best CIFAR-10 Accuracy: 89.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "111Sst3-oXOP"
      },
      "outputs": [],
      "source": [
        "# net.eval()\n",
        "# correct, total = 0, 0\n",
        "# with torch.no_grad():\n",
        "#     for img, target in loader[\"test\"]:\n",
        "#         img, target = img.to(device), target.to(device)\n",
        "\n",
        "#         # make prediction\n",
        "#         pred = net(img)\n",
        "\n",
        "#         # accumulate\n",
        "#         total += len(target)\n",
        "#         correct += (torch.argmax(pred, dim=1) == target).sum().item()\n",
        "\n",
        "# print(f\"Accuracy of the network on the {total} test images: {100 * correct / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST Adaptation 🔄 Simplified architecture\n",
        "\n",
        "net = nn.Sequential(\n",
        "    nn.Conv2d(1,32, 3),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.LeakyReLU(),\n",
        "\n",
        "    nn.Conv2d(32, 64, 3),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.LeakyReLU(),\n",
        "\n",
        "    nn.Conv2d(64,128,3),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.LeakyReLU(),\n",
        "\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(128*22*22, 128),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(128, 10)\n",
        ")\n",
        "\n",
        "# Ensure entire model is on device\n",
        "net = net.to(device)"
      ],
      "metadata": {
        "id": "hnorexJmVXdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch and torchvision provide some very handy utilities for dataset loading\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as tv_datasets\n",
        "import torchvision.transforms as tv_transforms"
      ],
      "metadata": {
        "id": "HmnTQnQChgxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare datasets\n",
        "dataset, loader = {}, {}\n",
        "for data_type in (\"train\", \"test\"):\n",
        "    is_train = data_type==\"train\"\n",
        "    dataset[data_type] = tv_datasets.MNIST(\n",
        "        root=\"./data\", train=is_train, download=True,\n",
        "        transform=tv_transforms.Compose([ # preprocessing pipeline for input images\n",
        "            tv_transforms.ToTensor(),\n",
        "            tv_transforms.Normalize((0.1307,), (0.3081,)),\n",
        "    ]))\n",
        "    loader[data_type] = DataLoader(\n",
        "        dataset[data_type], batch_size=batch_size, shuffle=is_train, num_workers=num_workers,\n",
        "    )\n"
      ],
      "metadata": {
        "id": "waiR8DKBVr7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "num_workers = 2\n",
        "print_every = 100\n",
        "\n",
        "optim_name = \"Adam\"\n",
        "optim_kwargs = dict(\n",
        "    lr=3e-4,\n",
        "    weight_decay=1e-6,\n",
        ")\n",
        "optimizer = getattr(optim, optim_name)(net.parameters(), **optim_kwargs)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# training loop\n",
        "net.train()\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, (img, target) in enumerate(loader[\"train\"]):\n",
        "        img, target = img.to(device), target.to(device)\n",
        "\n",
        "        pred = net(img)\n",
        "        loss = criterion(pred, target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % print_every == print_every - 1:\n",
        "            print(f\"[epoch={epoch + 1:3d}, iter={i + 1:5d}] loss: {running_loss / print_every:.3f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDO4e0I9XmAZ",
        "outputId": "6184c669-6cdb-45f9-c1f3-6af6b40da51f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch=  1, iter=  100] loss: 0.323\n",
            "[epoch=  1, iter=  200] loss: 0.099\n",
            "[epoch=  2, iter=  100] loss: 0.066\n",
            "[epoch=  2, iter=  200] loss: 0.057\n",
            "[epoch=  3, iter=  100] loss: 0.046\n",
            "[epoch=  3, iter=  200] loss: 0.046\n",
            "[epoch=  4, iter=  100] loss: 0.036\n",
            "[epoch=  4, iter=  200] loss: 0.036\n",
            "[epoch=  5, iter=  100] loss: 0.028\n",
            "[epoch=  5, iter=  200] loss: 0.027\n",
            "[epoch=  6, iter=  100] loss: 0.023\n",
            "[epoch=  6, iter=  200] loss: 0.021\n",
            "[epoch=  7, iter=  100] loss: 0.016\n",
            "[epoch=  7, iter=  200] loss: 0.019\n",
            "[epoch=  8, iter=  100] loss: 0.016\n",
            "[epoch=  8, iter=  200] loss: 0.016\n",
            "[epoch=  9, iter=  100] loss: 0.017\n",
            "[epoch=  9, iter=  200] loss: 0.019\n",
            "[epoch= 10, iter=  100] loss: 0.013\n",
            "[epoch= 10, iter=  200] loss: 0.017\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for img, target in loader[\"test\"]:\n",
        "        img, target = img.to(device), target.to(device)\n",
        "\n",
        "        # make prediction\n",
        "        pred = net(img)\n",
        "\n",
        "        # accumulate\n",
        "        total += len(target)\n",
        "        correct += (torch.argmax(pred, dim=1) == target).sum().item()\n",
        "\n",
        "print(f\"Accuracy of the network on the {total} test images: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "id": "_bnuj8hhgezw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48be12c8-eb4b-474c-820e-cacbc448ece8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 99.05%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}